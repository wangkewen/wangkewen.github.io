<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>CSC8530</title>
<link rel="stylesheet" href="style.css" type="text/css">
</head>
<body>
<div id="content">
<div id="header">
<span id="course"> CSC8530 </span>
<span id="sign">Kewen Wang</span>
</div>
<div id="leftcontent"> 
<a href="index.html"><img id="logo" src="MapReduce.png" alt="LOGO"></a>
<div id="taskslist">Tasks List</div>
<div id="nav">
<ul id="list">
<li class="task"><a class="tasklink" href="index.html">Topic Selection</a></li>
<li class="task"><a class="tasklink" href="paperlist.html">Bibliography of literature found</a></li>
<li class="task"><a class="tasklink" href="comment.html">Annotated Bibliography of the literature found</a></li>
<li class="task"><a class="tasklink" href="result.html">Detailed Annotated Bibliography and Classification of the Results</a></li>
<li class="task"><a class="tasklink" href="survey.html">Survey Paper</a></li>
</ul>
</div>
<div id="contact">Contact</div>
<div id="email">kwang12@student.gsu.edu</div>
</div>
<div id="rightcontent">
<h1>Brief Comment</h1>
<ul id="paperlist">
<li class="paper"><a href="http://idning-ebook.googlecode.com/svn/trunk/google/%23mapreduce-osdi04.pdf">MapReduce: Simplified data processing on large clusters. <i>(2004)</i></a>
<div class="comments">This paper introduces MapReduce programming model from Google Inc. In this paper, the authors provide the execution of MapReduce job and tasks assignment. And it describes some main functions: partitioning, ordering, combiner and so on. Moreover, this paper lists interesting programs that can be implemented by MapReduce computation, and uses grep and sort programs to measure the performance of MapReduce.</div></li>
<li class="paper"><a href="http://belkcollegeofbusiness.uncc.edu/JaredHansen/Teaching/Teaching%20Helps/DeanGhemawatACMJan2010.pdf">MapReduce: A Flexible Data Processing Tool. <i>(2010)</i></a>
<div class="comments">This paper compares MapRedue with parallel databases from many aspects: heterogeneous systems environment, data indices, program functions, structured data and schemas, fault tolerance and performance. In this paper, the authors claim that MapReduce has significant advantages over parallel databases. This paper mainly consists of brief ideas and opinions, and seems to be a summary.</div></li>
<li class="paper"><a href="https://www.cs.duke.edu/~hero/files/dataeng13-whatifengine.pdf">A What-if Engine for Cost-based MapReduce Optimization. <i>(2013)</i></a>
<div class="comments">This paper describes What-if Engine, a critical component of Starfish, a tool for optimizing MapReduce by tuning configurations of MapReduce job. Actually, What-if Engine is used to predict MapReduce job execution time (cost) with chosen MapReduce parameter configuration. In this paper, What-if Engine provides an analytical model to estimate dataflow and cost for MapReduce job.</div></li>
<li class="paper"><a href="http://arxiv.org/pdf/1302.2966.pdf">The Family of MapReduce and Large Scale Data Processing Systems. <i>(2013)</i></a>
<div class="comments">This paper describes the framework of MapReduce, and provides some techniques that can improve the performance and capabilities of MapReduce from different perspectives. In this paper, it covers various large scale data processing systems based on idea of MapReduce, similar to MapReduce or implemented on the top of MapReduce framework.</div></li>
<li class="paper"><a href="http://www.cs.duke.edu/~hero/files/vldb11-job-optimization.pdf">Profiling, what-if analysis, and cost-based optimization of MapReduce programs. <i>(2011)</i></a>
<div class="comments">This paper introduces a method to optimize MapReduce program by tunning MapReduce parameter configurations. In this paper, authors describes three main components of this method: profiler (used to collect statistical information related to MapReduce job cost), what-if engine (to predict the cost of a virtual MapReduce job with different configuration) and cost-based optimizer (to apply search algorithm to find the optimal configuration setting).</div></li>
<li class="paper"><a href="http://www.datascienceassn.org/sites/default/files/Minimal%20MapReduce%20Algorithms.pdf">Minimal MapReduce Algorithms. <i>(2013)</i></a>
<div class="comments">This paper presents the conception of minimal MapReduce algorithm, which could provide best parallelization. This idea is generated from the attempt to justify why TeraSort (a MapRedue program for sorting) achieves excellent performance. In this paper, TeraSort is modified to fit the rules provided by the authors to be a minimal algorithm, and the authors describe how this minimal algorithm could be applied to solve some database problems.</div></li>
<li class="paper"><a href="http://islab.kaist.ac.kr/chungcw/InterConfPapers/km0805-ha-myung.pdf">An Efficient MapReduce Algorithm for Counting Triangles in a Very Large Graph. <i>(2013)</i></a>
<div class="comments">This paper provides an efficient MapReduce algorithm to count the triangles in a large graph by solving the problem of redundant computation of triangles in previous algorithms. This new algorithm adds the step of triangle type classification to avoid this drawback. Moreover, this paper uses real-world dataset to demonstrate this new algorithm’s performance in large and dense graph.</div></li>
<li class="paper"><a href="http://www.chinacloud.cn/upload/2013-10/13100807567165.pdf">JackHare: a framework for SQL to NoSQL translation using MapReduce. <i>(2013)</i></a>
<div class="comments">This paper proposes a framework JackHare to translate SQL to MapReduce phases for processing the unstructured data in HBase. In this paper, authors analyze the methods about how to translate basic or extended SQL statements and the combination of SQL clauses to an execution plan of MapReduce phases. Besides, this paper explains the data model in HBase, a NoSQL database.</div></li>
<li class="paper"><a href="http://conferences.sigcomm.org/sigcomm/2013/papers/hotplanet/p27.pdf">Efficient social network data query processing on MapReduce. <i>(2013)</i></a>
<div class="comments">This paper presents an efficient method to translate SPARQL (a query language for processing social network data). This method consists of two primitives: using multiple-join-with-filter to substitute SQL join and merging the selection stage’s job into the join stage’s job. And the experiment on social network benchmarks demonstrates this method’s 2x speedup compared to the traditional method.</div></li>
<li class="paper"><a href="http://arxiv.org/ftp/arxiv/papers/1104/1104.3217.pdf">Automatic optimization for MapReduce programs. <i>(2011)</i></a>
<div class="comments">This paper describes a system MANIMAL to automatically optimize MapReduce programs. It is a data-aware optimization method, which does not change the MapReduce programs. This system MANIMAL consists of three components: analyzer (examines MapReduce programs and sends optimization descriptor to optimizer), optimizer (choose optimized execution plan sent to execution fabric) and execution fabric (execution the plan as MapReduce).</div></li>
<li class="paper"><a href="http://arxiv.org/pdf/1303.3517.pdf">Iterative mapreduce for large scale machine learning. <i>(2013)</i></a>
<div class="comments">This paper provides a method to make MapReduce to support iteration for machine learning. In this paper, authors explain an iterative MapReduce programming model for machine learning. And the paper presents an optimizer to provide theoretically optimal choices for the fan-in f and the number of machines N to be used, and evaluates the optimizer by experiments.</div></li>
<li class="paper"><a href="http://crpit.com/confpapers/CRPITV152Hsueh.pdf">A Load-Balanced MapReduce Algorithm for Blocking-based Entity-resolution with Multiple Keys. <i>(2014)</i></a>
<div class="comments">This paper proposes a MapReduce algorithm to solve the Entity Resolution (known as data matching) problem in a large collection of entities with multiple keys. This algorithm consists of two main steps: combination-based blocking (produces potential key combinations and distributes entity lists having common keys) and load-balanced matching (generates entity-pairs combinations and balances the workloads of similarity computations).</div></li>
<li class="paper"><a href="http://static.usenix.org/events/nsdi10/tech/full_papers/condie.pdf">MapReduce Online. <i>(2010)</i></a>
<div class="comments">This paper develops a pipelining version of Hadoop: Hadoop Online Prototype (HOP). HOP extends Hadoop to support pipelining between tasks and between jobs. In this paper, authors explains how HOP supports online aggregation within a single job and between multiple jobs, and also describes how HOP enables MapReduce jobs that run continuously to accept new data and analyze it immediately.</div></li>
<li class="paper"><a href="http://arxiv.org/pdf/1203.5387.pdf">Finding connected components in map-reduce in logarithmic rounds. <i>(2013)</i></a>
<div class="comments">This paper proposes two new algorithms for connected components computation in large graph: Hash-to-MIin algorithm and Hash-Greater-to-Min algorithm. These two algorithms apply hashing strategies to achieve logarithmic rounds and less communication cost. In this paper, authors use a variety of real datasets to evaluate the performance of these two algorithms.</div></li>
<li class="paper"><a href="http://arxiv.org/pdf/1207.0141.pdf">Efficient processing of k nearest neighbor joins using mapreduce. <i>(2012)</i></a>
<div class="comments">This paper introduces a method to apply MapReduce to process k nearest neighbor join (kNN), which is widely used in data mining and analysis applications like k-means clustering. This method consists of three main steps: data preprocessing, first MapReduce and second MapReduce. Moreover, this paper presents a cost model and two grouping strategies to minimize the replicas of data in order to reduce the shuffling cost between Map and Reduce.</div></li>
<li class="paper"><a href="http://rio.ecs.umass.edu/mnilpub/papers/hpdc2013-yin.pdf">Efficient analytics on ordered datasets using MapReduce. <i>(2013)</i></a>
<div class="comments">This paper proposes a novel mechanism to apply MapReduce/Hadoop to efficiently execute RE-ORG task (Relative Order-pReserving based Grouping), which is often used in event log files analysis. This mechanism defines three phases group-order-merge (GOM) to replace the sort-merge shuffle scheme to improve the execution performance of RE-ORG task in a distributed environment.</div></li>
<li class="paper"><a href="http://simplemonitoring.googlecode.com/svn-history/r235/trunk/document/paper/paper.pdf">Google’s MapReduce Programming Model — Revisited. <i>(2008)</i></a>
<div class="comments">This paper is an analytical article about MapReduce and Sawzall of Google. This paper presents the details of MapReduce and help to further understand the underlying concepts and resolve some obscurities in the informal presentation of the previous papers from Google. This paper uses reverse-engineering mode to extract an executable specification for MapReduce computation, and describes the parallelism in a distributed execution of MapReduce computations.</div></li>
<li class="paper"><a href="http://markus-h.github.io/stratosphere/assets/papers/optimizationOfDataFlowsWithUDFs_13.pdf">Peeking into the Optimization of Data Flow Programs with MapReduce-style UDFs. <i>(2013)</i></a>
<div class="comments">This paper provides an optimizer for data flow programs with MapReduce style user-defined functions (UDFs). This paper constructs a Pact programming model (a generalization of the MapReduce programming model) to describe the programs to be optimized. This optimizer analyzes the static code changes the operator order and choose physical execution plans to achieve the optimization.</div></li>
<li class="paper"><a href="http://cseweb.ucsd.edu/~avattani/papers/mrgreedy.pdf">Fast Greedy Algorithms in MapReduce and Streaming. <i>(2013)</i></a>
<div class="comments">This paper shows a new method to efficiently realize greedy algorithms (like modular maximization and monotone submodular maximization). This method is sample&prune, which could progressively reduce the size of the input. Moreover, this paper discusses how the algorithms given extend to streaming models. And authors use real world datasets to validate the algorithms.</div></li>
<li class="paper"><a href="http://www.vldb.org/pvldb/vol6/p1230-mokbel.pdf">A Demonstration of SpatialHadoop: An Efficient MapReduce Framework for Spatial Data. <i>(2013)</i></a>
<div class="comments">This paper describes SpatialHadoop, which is designed to efficiently process spatial data compared with Hadoop. SpatialHadoop takes spatially indexed files as input and introduces SpatialFileSplitter to exploit global indexes and SpatialRecordReader to exploit local indexes. SpatialHadoop has supported three spatial operations: range queries, k-nearest-neighbor queries and spatial join.</div></li>
<li class="paper"><a href="https://ece.uwaterloo.ca/~aelgohar/Farahat_CSS_ICDM2013.pdf">Distributed Column Subset Selection on MapReduce. <i>(2013)</i></a>
<div class="comments">This paper proposes a MapReduce program to solve Colum Subset Selection (CSS) problem that is defined as the selection of the most representative columns of a data matrix. This algorithm firstly learns a concise representation of the data matrix by using random projection and then applies a centralized greedy algorithm for CSS to perform the selection from different sub-matrices.</div></li>
<li class="paper"><a href="http://www.vldb.org/pvldb/vol7/p241-onizuka.pdf">Optimization for iterative queries on MapReduce. <i>(2013)</i></a>
<div class="comments">This paper describes a system OptIQ to optimize iterative queries on MapReduce, OptIQ removes redundant computations among different iterations. It involves two ideas: table decomposition & materialization (detects modified attributes among iterations, extracts maximum subqueries in iterative queries and materializes the subqueries) and Automatic incrementalization (automatically detects the modified tuples among iterations and incrementally evaluates the iterative query for those tuples).</div></li>
<li class="paper"><a href="http://pdf.aminer.org/000/225/039/a_practical_approach_to_static_node_positioning.pdf">SQL/MapReduce: A practical approach to self-describing, polymorphic, and parallelizable user-defined functions. <i>(2009)</i></a>
<div class="comments">This paper presents SQL/MapReduce (SQL/MR), a new framework for User-Defined Functions (UDFs). It is parallel designed to process parallel computation in massively-parallel relational database. Query syntax of SQL/MR is similar to SQL query, and the execution model provided by SQL/MR functions is a generalization of MapReduce.</div></li>
<li class="paper"><a href="http://www.cse.ohio-state.edu/hpcs/WWW/HTML/publications/papers/TR-11-7.pdf">Ysmart: Yet another sql-to-mapreduce translator. <i>(2011)</i></a>
<div class="comments">This paper presents a system YSmart that is built on the top of Hadoop to translate SQL query into MapReduce programs. YSmart is designed as a translator with specific considerations of intra-query correlations to improve execution efficiency. In this paper, authors apply experiments to demonstrate its performance over Hive and Pig, two widely-used translators from SQL to MapReduce.</div></li>
<li class="paper"><a href="http://arxiv.org/pdf/1211.6176.pdf">Shark: SQL and rich analytics at scale. <i>(2013)</i></a>
<div class="comments">This paper designs a data analysis system Shark to provide the support for efficient SQL query processing and sophisticated machine learning by using SQL. Shark generalizes a MapReduce-like runtime to run SQL effectively, and Spark is the MapReduce-like cluster computing engine of Shark. The main abstraction of Spark is resilient distributed datasets (RDDs).</div></li>
<li class="paper"><a href="http://vldb.org/pvldb/vol5/p2014_jensdittrich_vldb2012.pdf">Efficient Big Data Processing in Hadoop MapReduce. <i>(2012)</i></a>
<div class="comments">This is a paper to propose some ideas to optimize Hadoop MapReduce. It presents the topics about tuning the configuration parameters of Hadoop MapReduce jobs and query optimization techniques for Hadoop MapReduce jobs. Besides, it points out the performance problems in Hadoop MapReduce: data layouts in different nodes and lack of appropriate indexes for MapReduce jobs.</div></li>
<li class="paper"><a href="http://pasa-bigdata.nju.edu.cn/people/ronggu/pub/SHadoop_JPDC.pdf">SHadoop: Improving MapReduce performance by optimizing job execution mechanism in Hadoop clusters. <i>(2014)</i></a>
<div class="comments">This paper presents an optimized version of Hadoop: SHadoop, to improve the execution performance of MapReduce jobs. SHadoop optimizes setup/cleanup tasks in MapReduce job to shorten the startup and cleanup time and optimizes job/tasks execution event notification mechanism to provide an instant messaging communication mechanism for efficient critical event notification.</div></li>
<li class="paper"><a href="https://lambda.uta.edu/mrql.pdf">An optimization framework for map-reduce queries. <i>(2012)</i></a>
<div class="comments">This paper presents a novel MapReduce-like query language for map-reduce computations: MRQL (Map-Reduce Query Language). It designs and implements an effective optimization framework for Map-Reduce queries. This paper provides details about how to translate MRQL queries to efficient execution of MapReduce jobs. Besides, this paper compares MRQL with HiveQL and PigLatin that are popular MapReduce query languages.</div></li>
<li class="paper"><a href="http://www.ics.uci.edu/~ramang/RamanGrover/Home_files/predicate_based_sampling_grover_carey.pdf">Extending map-reduce for efficient predicate-based sampling. <i>(2012)</i></a>
<div class="comments">This paper provides a new mechanism to provide efficient predicate-based sampling using MapReduce. It treats predicate-based sampling as a SQL query. In this paper, authors introduce a concept of Input Provider into Hadoop execution model. Input Provider could realize the dynamic decision making regarding the job input, and finally achieve an incremental processing mechanism that could improve the performance of predicate-based sampling.</div></li>
<li class="paper"><a href="http://www.infosun.fim.uni-passau.de/cl/publications/docs/DAL13mapreduce.pdf">Modeling and Optimizing MapReduce Programs. <i>(2013)</i></a>
<div class="comments">It is a technical report about MapReduce optimization. It represents MapReduce programming model from the aspect of functional model, and analyzes main steps of MapReduce execution: Mapper, shuffle and Reducer. Besides, it constructs a cost model to analyze the time cost of MapReduce programs. Based on the models, it provides rules for optimization and demonstrates the effectiveness.</div></li>
<li class="paper"><a href="http://ceur-ws.org/Vol-1133/paper-02.pdf">Binary Theta-Joins using MapReduce: Efficiency Analysis and Improvements. <i>(2014)</i></a>
<div class="comments">This paper proposes the methods to improve the efficiency of binary theta-joins using MapReduce. It uses a join matrix (JM) to represent the workload partitioned across the reducers. This paper discusses how to improve the algorithms 1-Bucket-Theta and M-Bucket, which are the algorithms for theta-joins in MapReduce. Proposal of the paper could reduce the communication cost and lead to maximum reducer input.</div></li>
<li class="paper"><a href="http://cloud.pubs.dbs.uni-leipzig.de/sites/cloud.pubs.dbs.uni-leipzig.de/files/Jiang2010TheperformanceofmapreduceAnindepthstudy.pdf">The Performance of MapReduce: An In-depth Study. <i>(2010)</i></a>
<div class="comments">This paper is about the research of MapReduce performance. It discusses five factors that affect the performance of MapReduce: I/O mode of the storage system, data parsing for key/value pair record, indexing for data blocks, MapReduce programming model and runtime scheduling scheme applied in MapReduce. And the paper uses experiments to demonstrate the performance improvement by tuning these factors.</div></li>
<li class="paper"><a href="https://www.cs.duke.edu/~shivnath/papers/socc2010.pdf">Towards automatic optimization of MapReduce programs. <i>(2010)</i></a>
<div class="comments">In this paper, author provides a new idea to optimize the MapReduce job performance by tuning MapReduce parameters. This paper analyzes some MapReduce parameters’ impact on the MapReduce job and the interactions among parameters. Moreover, author proposes some potential approaches of tuning parameter configuration such as database query-optimizer-style approach and dynamic profiling.</div></li>
</ul>
</div>
<div id="footer"></div>

</div>
</body>
</html>
